{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Educación Continua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan librerías de pandas, numpy, matplotlib y seabron; de minisom, se importó el módulo MiniSom, del módulo sklearn.cluster se importó la clase KMeans y del módulo sklearn.metrics, se importó pairwise_distances_argmin_min.\n",
    "\n",
    "%matplotlib inline es una 'magic function' de iPython. El propósito de esta línea de código es que los plots de matplotlib se desplieguen dentro de la misma celda y justo debajo del código que llama a la librería. plt.rcParams se utiliza para controlar el tamaño de las gráficas. plt.style.use es para seleccionar un estilo de gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By José Francisco Pacheco Quintana a.k.a. 'pach'\n",
    "#Importing libraries needed for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pprint\n",
    "import c45\n",
    "\n",
    "from minisom import MiniSom\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    " \n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rcParams['figure.figsize'] = (30, 20) \n",
    "plt.rc('font', size=20) \n",
    "#Determines the size of the graphs\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se creó un dataframe que consiste con los datos obtenidos de las ECOAS. Se eliminaron ciertas columnas que se cree que son irrelevantes para el análisis de la información (además de que se libera espacio de memoria y facilita el procesamiento): se descartó comentario porque ya se tiene el puntaje del comentario; correo_coordinador y correo_instructor porque ya se tiene una columna con los nombres de los coordinadores e instructores por lo que esta información sería un tanto redundante para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a dataframe from excel file\n",
    "df = pd.read_excel (r'comments_final.xlsx')\n",
    "#Getting rid of unuseful data\n",
    "clean_data = df.drop(['comentario', 'correo_coordinador', 'correo_instructor'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se creó un dataframe que consiste únicamente en las columnas nps y puntaje_sentimiento. Se borraron los campos que tenían datos que contienen campos vacíos, ya que algunos algoritmos no se puede aplicar a campos vacíos. Posteriormente se creó un histograma de las columnas nps y puntaje_sentimiento, para mostrar la distribución de los datos. Se puede observar en las tablas que la mayor parte de los registros tienen un nps en el percentil más alto, mientras que para puntaje_sentimiento, se puede observar que la mayor parte de los registros tienen un puntaje neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe with relevant numerical values: nps and puntaje_sentimiento\n",
    "data_km = clean_data[['puntaje_sentimiento', 'nps']].copy()\n",
    "data_km = data_km.dropna()\n",
    "#Creating an histogram for showing the distribution of puntaje_sentimiento agains nps\n",
    "data_km.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se creó un array X de dos dimensiones con las columnas del dataframe data_km. Posteriormente, se introdujo el array a una función del módulo KMeans, con el propósito de determinar el número de clusters en los que se puede agrupar los registros introducidos. Se utilizó el método de evaluación de distancias entre los datos y los centroides. En la gráfica, score corresponde a esta distancia. Se puede observar que cuando la curva llega a 5, se produce un 'codo', indicando que este es un número de clusters ideal para los datos introducidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>K-Means algorithm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data_km[[\"puntaje_sentimiento\", \"nps\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the number of clusters\n",
    "Nc = range(1, 20)\n",
    "kmeans = [KMeans(n_clusters=i) for i in Nc]\n",
    "kmeans\n",
    "score = [kmeans[i].fit(X).score(X) for i in range(len(kmeans))]\n",
    "score\n",
    "plt.plot(Nc,score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica el algoritmo K-Means a las columnas de nps y puntaje_sentimiento. El algoritmo de K-means clasifica los datos introducidos midiendo las distancias euclidianas entre los registros y los centroides, realizando múltiples iteraciones hasta que se llega a una en la cual las distancias sean óptimas. También se obtienen los centroides de cada cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying K-Means algorithm to the nps and puntaje_sentimiento columns from the data\n",
    "kmeans = KMeans(n_clusters=5).fit(data_km)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)\n",
    "\n",
    "plt.scatter(data_km['puntaje_sentimiento'], data_km['nps'], c= kmeans.labels_.astype(float), s=50, alpha=0.5)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca entre los registros aquellos que son más cercanos a cada uno de los centroides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining the id of the registers that are the closest to each centroid\n",
    "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, data_km)\n",
    "closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = data_km.index.values\n",
    "cluster_map['cluster'] = kmeans.labels_\n",
    "\n",
    "new_column = cluster_map[['cluster']]\n",
    "\n",
    "merged = clean_data.merge(new_column, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "writer = ExcelWriter('comments_cluster.xlsx')\n",
    "merged.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.dropna()\n",
    "dict_of_cluster = {k: v for k, v in merged.groupby('cluster')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust = dict_of_cluster[0]\n",
    "\n",
    "dict_by_campus = {k: v for k, v in df_clust.groupby('campus')}\n",
    "\n",
    "dict_by_inst = {k: v for k, v in df_clust.groupby('instructor')}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de estadísticas por campus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = dict_by_campus['AGS (Aguascalientes)']\n",
    "\n",
    "campus_mode = A.drop(['categoria', 'subcategoria', 'fecha_coordinador', 'campus', 'cluster', 'id'], axis = 1)\n",
    "\n",
    "print(campus_mode.mode())\n",
    "print(A.mean(axis = 0, skipna = True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de estadísticas por instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = dict_by_inst['ANA LOURDES LOPEZ MONDRAGON']\n",
    "\n",
    "inst_mode = B.drop(['categoria', 'subcategoria', 'fecha_coordinador', 'campus', 'cluster', 'instructor', 'id'], axis = 1)\n",
    "\n",
    "print(inst_mode.mode())\n",
    "print(B.mean(axis = 0, skipna = True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Análisis por grupo </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = pd.read_excel (r'comments_grupo.xlsx')\n",
    "dict_by_group = {k: v for k, v in group_data.groupby('grupo')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupo 2:\n",
    "Campus Ciudad Juárez y Campus Central de Veracruz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Campus Ciudad Juárez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data2 = dict_by_group[2]\n",
    "dict_by_camp = {k: v for k, v in group_data.groupby('campus')}\n",
    "camp_cdj = dict_by_camp['CDJ (Cd. Juárez)']\n",
    "\n",
    "low = camp_cdj.loc[(camp_cdj['nps'] < 75)]\n",
    "mode = low.drop(['id', 'correo_instructor', 'grupo'], axis = 1)\n",
    "\n",
    "print('modas: ')\n",
    "print('')\n",
    "print(mode.mode())\n",
    "print('')\n",
    "print('promedios: ')\n",
    "print('')\n",
    "print(low.mean(axis = 0, skipna = True))\n",
    "print('')\n",
    "print('desviación estándar: ')\n",
    "print('')\n",
    "print(low.std(axis = 0, skipna = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def estadisticas(campus)\n",
    "\n",
    "I = low['instructor'].unique()\n",
    "for x in I:\n",
    "    inst = camp_cdj.loc[(camp_cdj['instructor'] == x)]\n",
    "    inst_est = inst.drop(['id', 'correo_instructor', 'grupo', 'campus', 'id_programa', 'id_modulo'], axis = 1)\n",
    "    print('promedios de ' + x)\n",
    "    print('')\n",
    "    print(inst_est.mean(axis = 0, skipna = True))\n",
    "    print('')\n",
    "    print('desviaciones estándar de  ' + x)\n",
    "    print('')\n",
    "    print(inst_est.std(axis = 0, skipna = True))\n",
    "    print('')\n",
    "    print('medianas de  ' + x)\n",
    "    print('')\n",
    "    print(inst_est.median(axis = 0, skipna = True))\n",
    "    print('______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(low['instructor'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupo 3: Campus Ciudad Obregón, Campus Cuernavaca, Campus Hidalgo y Campus Irapuato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data3 = dict_by_group[3]\n",
    "print(group_data3['campus'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Naïve Bayes Algorithm (Development)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None,\n",
    "                   names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.label.map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df.message.map(lambda x: x.lower())\n",
    "df['message'] = df.message.str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# This converts the list of words into space-separated strings\n",
    "df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "counts = count_vect.fit_transform(df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "print(model)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up data\n",
    "\n",
    "merged = merged.dropna()\n",
    "NB_data = merged[['tipo', 'campus', 'id_programa', 'nps', 'id_modulo', 'instructor', 'nombre_coordinador', 'indicador', 'categoria', 'subcategoria']].copy()\n",
    "NB_data['nps75'] = (NB_data['nps'] >= 75)\n",
    "NB_data = NB_data.drop(['nps'], axis = 1)\n",
    "NB_data[\"id_programa\"]= NB_data[\"id_programa\"].astype(str)\n",
    "NB_data[\"id_modulo\"]= NB_data[\"id_modulo\"].astype(str)\n",
    "NB_data[\"nps75\"]= NB_data[\"nps75\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = NB_data[['tipo', 'nps75']].copy()\n",
    "counts = test.values\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, test[['tipo', 'nps75'] ], test_size=0.1, random_state=69)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1R Algorithm (Development)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_excel (r'Test.xlsx')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the types of the columns to strings and booleans\n",
    "print(test.dtypes)\n",
    "\n",
    "\n",
    "for col in test.columns:\n",
    "    if(test[col].dtype == np.object or test[col].dtype == np.bool):\n",
    "          pass\n",
    "    else:\n",
    "          test[col] = test[col].astype(str)\n",
    "print(test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "#print(test['Outlook'])\n",
    "a = test['Outlook'].value_counts()\n",
    "target = test['Play'].value_counts()\n",
    "#length_target = target.size\n",
    "#length = a.size\n",
    "x = 0\n",
    "gkk = test.groupby(['Outlook'])\n",
    "print(gkk)\n",
    "\n",
    "\n",
    "\"\"\"while x < length:\n",
    "    numerator = a.iloc[x]\n",
    "    print(a.iloc[x])\n",
    "    \n",
    "    x = x+1 \n",
    "\"\"\"\n",
    "#if a(sunny) > a.iloc[:2]:\n",
    " \n",
    "    #print(a[:0])\n",
    "#else:\n",
    " #   pass\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CART Algorithm (Development)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing with sample dataset\n",
    "import decision_tree as dt\n",
    "dec_tree = test.values #converting the dataframe into an array\n",
    "my_tree = dt.build_tree(dec_tree)\n",
    "dt.print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "writer = ExcelWriter('nps75.xlsx')\n",
    "NB_data.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nps75 = pd.read_excel (r'nps75.xlsx')\n",
    "\n",
    "for col in nps75:\n",
    "    nps75[col] = [np.nan if (not isinstance(val, str) and np.isnan(val)) else \n",
    "               (val if isinstance(val, str) else str(int(val))) \n",
    "               for val in nps75[col].tolist()]\n",
    "\n",
    "print(nps75.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the dataframe\n",
    "import decision_tree as dt\n",
    "dec_tree = nps75.values #converting the dataframe into an array\n",
    "my_tree = dt.build_tree(dec_tree)\n",
    "dt.print_tree(my_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
